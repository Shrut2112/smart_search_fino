{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260646d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports loaded\n",
      "ğŸ“ PDF_DIR: data\\pdfs\n",
      "ğŸ“ CHUNKS_DIR: data\\chunks\n",
      "ğŸ“„ METADATA: True\n",
      "ğŸ“„ FAQ: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain for chunking & embeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Paths\n",
    "PDF_DIR = Path(\"data/pdfs\")\n",
    "CHUNKS_DIR = Path(\"data/chunks\")\n",
    "METADATA_PATH = Path(\"metadata/canonical/fino_policies_metadata.json\")\n",
    "FAQ_PATH = Path(\"data/raw/fino_full_qa_dump.txt\")  \n",
    "\n",
    "# Create directories\n",
    "PDF_DIR.mkdir(exist_ok=True)\n",
    "CHUNKS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Imports loaded\")\n",
    "print(f\"ğŸ“ PDF_DIR: {PDF_DIR}\")\n",
    "print(f\"ğŸ“ CHUNKS_DIR: {CHUNKS_DIR}\")\n",
    "print(f\"ğŸ“„ METADATA: {METADATA_PATH.exists()}\")\n",
    "print(f\"ğŸ“„ FAQ: {FAQ_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a63b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Loaded 16 policy versions\n",
      "ğŸ¯ Active policies: 14\n",
      "ğŸ“‚ PDFs in data/pdfs/: 16\n",
      "âœ… All PDFs found\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load canonical metadata\n",
    "with open(METADATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    policies = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“‹ Loaded {len(policies)} policy versions\")\n",
    "print(f\"ğŸ¯ Active policies: {sum(1 for p in policies if p['status'] == 'Active')}\")\n",
    "print(f\"ğŸ“‚ PDFs in data/pdfs/: {len(list(PDF_DIR.glob('*.pdf')))}\")\n",
    "\n",
    "# Validate all PDF paths exist\n",
    "missing_pdfs = []\n",
    "for policy in policies:\n",
    "    pdf_path = PDF_DIR / policy['file_name']\n",
    "    if not pdf_path.exists():\n",
    "        missing_pdfs.append(policy['file_name'])\n",
    "\n",
    "if missing_pdfs:\n",
    "    print(f\"Missing {len(missing_pdfs)} PDFs:\")\n",
    "    for pdf in missing_pdfs[:5]:\n",
    "        print(f\"   - {pdf}\")\n",
    "else:\n",
    "    print(\"âœ… All PDFs found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Universal Extractor loaded (Layers 1-4)\n"
     ]
    }
   ],
   "source": [
    "def universal_extract(pdf_path: Path) -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    ROBUST EXTRACTION: Layer 1-4 (Blocks + Tables + Fallback + Cleaning)\n",
    "    Returns (full_text, extraction_stats)\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text_parts = []\n",
    "    extraction_stats = {\n",
    "        \"total_pages\": len(doc),\n",
    "        \"text_blocks\": 0,\n",
    "        \"table_blocks\": 0,\n",
    "        \"raw_chars\": 0\n",
    "    }\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # LAYER 1: BLOCKS (text + table structure)\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        page_content = []\n",
    "        \n",
    "        for block in blocks:\n",
    "            x0, y0, x1, y1, block_text, _, block_type = block\n",
    "            if block_text.strip():\n",
    "                if block_type == 0:  # Text block\n",
    "                    page_content.append(block_text)\n",
    "                    extraction_stats[\"text_blocks\"] += 1\n",
    "                else:  # Table/graphics\n",
    "                    rect = fitz.Rect(x0, y0, x1, y1)\n",
    "                    table_text = page.get_text(\"text\", clip=rect)\n",
    "                    if table_text.strip():\n",
    "                        page_content.append(f\"\\n[TABLE]{table_text.strip()}[/TABLE]\\n\")\n",
    "                        extraction_stats[\"table_blocks\"] += 1\n",
    "        \n",
    "        # LAYER 2: TABLES (PyMuPDF table detection)\n",
    "        tables = page.find_tables()\n",
    "        for table in tables:\n",
    "            try:\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                table_str = df.to_string(index=False, header=False)\n",
    "                page_content.append(f\"\\n[TABLE-DATA]\\n{table_str}\\n[/TABLE-DATA]\")\n",
    "                extraction_stats[\"table_blocks\"] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # LAYER 3: RAW FALLBACK\n",
    "        raw_text = page.get_text()\n",
    "        if raw_text.strip() and len(raw_text) > 50:\n",
    "            page_content.append(raw_text)\n",
    "            extraction_stats[\"raw_chars\"] += len(raw_text)\n",
    "        \n",
    "        # LAYER 4: Aggressive cleaning\n",
    "        page_text = \"\\n\\n\".join(page_content)\n",
    "        page_text = re.sub(r'Classification: Internal.*?(?=\\n{2,}|\\Z)', '', page_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        page_text = re.sub(r'FINO Payments Bank Limited\\s*\\n?', '', page_text, flags=re.IGNORECASE)\n",
    "        page_text = re.sub(r'^\\s*\\d+\\s*\\n?', '', page_text, flags=re.MULTILINE)\n",
    "        page_text = re.sub(r'\\n{5,}', '\\n\\n\\n', page_text)\n",
    "        page_text = re.sub(r'\\s{4,}', ' ', page_text)\n",
    "        \n",
    "        if len(page_text.strip()) > 30:\n",
    "            full_text_parts.append(page_text.strip())\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    full_text = \"\\n\\n=== PAGE BREAK ===\\n\\n\".join(full_text_parts)\n",
    "    extraction_stats[\"total_chars\"] = len(full_text)\n",
    "    extraction_stats[\"total_words\"] = len(full_text.split())\n",
    "    \n",
    "    return full_text, extraction_stats\n",
    "\n",
    "print(\"âœ… Universal Extractor loaded (Layers 1-4)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecde22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BGE-M3 specs\n",
    "# BGE_M3_MAX_TOKENS = 8192  # Context window\n",
    "# BGE_M3_MAX_CHUNK_CHARS = 4000  # Safe embedding limit (~75% of max)\n",
    "# CHUNK_OVERLAP_CHARS = 200  # Semantic overlap\n",
    "\n",
    "# print(f\"ğŸ”§ BGE-M3 Config:\")\n",
    "# print(f\"   Max tokens: {BGE_M3_MAX_TOKENS:,}\")\n",
    "# print(f\"   Max chunk chars: {BGE_M3_MAX_CHUNK_CHARS}\")\n",
    "# print(f\"   Overlap: {CHUNK_OVERLAP_CHARS} chars\")\n",
    "\n",
    "# # Initialize embeddings for semantic chunking\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "# print(\"âœ… BGE-M3 embeddings initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870c3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ E5-Large Config:\n",
      "   Max tokens: 1,024\n",
      "   Max chunk chars: 2000\n",
      "   Overlap: 200 chars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name D:/models/e5-large. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… E5-Large embeddings initialized\n"
     ]
    }
   ],
   "source": [
    "E5_MAX_TOKENS = 1024          # Effective context window for E5\n",
    "E5_MAX_CHUNK_CHARS = 2000     # Safe chunk size for embeddings\n",
    "CHUNK_OVERLAP_CHARS = 200     # Semantic overlap \n",
    "\n",
    "print(f\"ğŸ”§ E5-Large Config:\")\n",
    "print(f\"   Max tokens: {E5_MAX_TOKENS:,}\")\n",
    "print(f\"   Max chunk chars: {E5_MAX_CHUNK_CHARS}\")\n",
    "print(f\"   Overlap: {CHUNK_OVERLAP_CHARS} chars\")\n",
    "\n",
    "# Initialize embeddings for semantic chunking \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"D:/models/e5-large\"   # local multilingual-e5-large\n",
    ")\n",
    "\n",
    "print(\"âœ… E5-Large embeddings initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Processing 14 ACTIVE policies...\n",
      "\n",
      "[1/14] ğŸ“„ Comprehensive Deposit Policy - V7 (1).pdf\n",
      "   Policy: Comprehensive Deposit Policy - V7 (1).pdf...\n",
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n",
      "   ğŸ“Š Extraction: 76,348 chars, 11,270 words\n",
      "   ğŸ“Š Blocks: 224 text + 5 tables\n",
      "   âœ‚ï¸  68/88 valid chunks\n",
      "   ğŸ“ Saved: comprehensivedepositpolicy_7.json\n",
      "   ğŸ“ Sizes: 154-1982 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: Classification: Public Comprehensive Deposit Policy V7.0 \n",
      "Page 1 Comprehensive Deposit Policy Version 7.0 The policy as enclosed was last approved by ...\n",
      "\n",
      "[2/14] ğŸ“„ 1736412697_1362025_BSBDAPolicy.pdf\n",
      "   Policy: 1736412697_1362025_BSBDAPolicy.pdf...\n",
      "   ğŸ“Š Extraction: 33,523 chars, 5,138 words\n",
      "   ğŸ“Š Blocks: 185 text + 6 tables\n",
      "   âœ‚ï¸  29/40 valid chunks\n",
      "   ğŸ“ Saved: bsbdapolicy_1.json\n",
      "   ğŸ“ Sizes: 206-1485 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: 4 B. Regulatory reference ................................................................................................... 4 C. Policy content .......\n",
      "\n",
      "[3/14] ğŸ“„ 1733376480_DeceasedClaimSettlementPolicy.pdf\n",
      "   Policy: 1733376480_DeceasedClaimSettlementPolicy.pdf...\n",
      "   ğŸ“Š Extraction: 37,600 chars, 5,505 words\n",
      "   ğŸ“Š Blocks: 95 text + 8 tables\n",
      "   âœ‚ï¸  29/47 valid chunks\n",
      "   ğŸ“ Saved: deceasedclaimsettlementpolicy_1.json\n",
      "   ğŸ“ Sizes: 175-1594 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: FINO Payments Bank Deceased Claim Settlement Policy \n",
      "Version 1.0 Document review and approval July 2024 FINO Payments Bank \n",
      "Deceased Claim Settlement ...\n",
      "\n",
      "[4/14] ğŸ“„ Customer Compensation Policy.pdf\n",
      "   Policy: Customer Compensation Policy.pdf...\n",
      "   ğŸ“Š Extraction: 53,173 chars, 7,909 words\n",
      "   ğŸ“Š Blocks: 153 text + 5 tables\n",
      "   âœ‚ï¸  36/55 valid chunks\n",
      "   ğŸ“ Saved: customercompensationpolicy_1.json\n",
      "   ğŸ“ Sizes: 221-1358 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: FINO Payments Bank Customer Compensation Policy Version 11.0 \n",
      "FINO Payments Bank Customer Compensation Policy Version 11.0\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "FINO P...\n",
      "\n",
      "[5/14] ğŸ“„ Customer Grievance Policy_0.pdf\n",
      "   Policy: Customer Grievance Policy_0.pdf...\n",
      "   ğŸ“Š Extraction: 30,260 chars, 4,351 words\n",
      "   ğŸ“Š Blocks: 149 text + 1 tables\n",
      "   âœ‚ï¸  23/30 valid chunks\n",
      "   ğŸ“ Saved: customergrievancepolicy_1.json\n",
      "   ğŸ“ Sizes: 185-1660 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: FINO Payments Bank Customer Grievance Redressal Policy\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "Table of Contents \n",
      ". Policy Usage Guide .....................................\n",
      "\n",
      "[6/14] ğŸ“„ Code of Banks Commitment-to-Customers_0.pdf\n",
      "   Policy: Code of Banks Commitment-to-Customers_0.pdf...\n",
      "   ğŸ“Š Extraction: 44,713 chars, 6,928 words\n",
      "   ğŸ“Š Blocks: 107 text + 1 tables\n",
      "   âœ‚ï¸  44/58 valid chunks\n",
      "   ğŸ“ Saved: codeofbankscommittmenttocustomers_1.json\n",
      "   ğŸ“ Sizes: 168-1936 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: FINO Payments Bank Code of Bankâ€™s Commitment to  Customers Version 10.0 \n",
      "FINO Payments Bank \n",
      "Code of Bankâ€™s Commitment to  Customers Version 10.0\n",
      "\n",
      "===...\n",
      "\n",
      "[7/14] ğŸ“„ Customer Service Policy_0.pdf\n",
      "   Policy: Customer Service Policy_0.pdf...\n",
      "   ğŸ“Š Extraction: 212,375 chars, 31,705 words\n",
      "   ğŸ“Š Blocks: 535 text + 1 tables\n",
      "   âœ‚ï¸  179/231 valid chunks\n",
      "   ğŸ“ Saved: customerservicepolicy_1.json\n",
      "   ğŸ“ Sizes: 153-1940 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: Fino Payments Bank Customer Service Policy Version 13.0 \n",
      "Fino Payments Bank Customer Service Policy Version 13.0\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "Table of Content...\n",
      "\n",
      "[8/14] ğŸ“„ 1683371692_KYCAMLCFTPolicy.pdf\n",
      "   Policy: 1683371692_KYCAMLCFTPolicy.pdf...\n",
      "   ğŸ“Š Extraction: 116,623 chars, 18,263 words\n",
      "   ğŸ“Š Blocks: 1706 text + 3 tables\n",
      "   âœ‚ï¸  71/100 valid chunks\n",
      "   ğŸ“ Saved: revisedkyc_wef2ndmay2023_1.json\n",
      "   ğŸ“ Sizes: 154-1979 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: KYC / AML / CFT Policy Version 4.0\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "INDEX Chapter\n",
      "Title\n",
      "Page No. I \n",
      "Introduction and applicability \n",
      "II \n",
      "Definitions \n",
      "III \n",
      "Customer...\n",
      "\n",
      "[9/14] ğŸ“„ 1690896825_PrivacyPolicyforMitraapplication.pdf\n",
      "   Policy: 1690896825_PrivacyPolicyforMitraapplication.pdf...\n",
      "   ğŸ“Š Extraction: 36,247 chars, 5,764 words\n",
      "   ğŸ“Š Blocks: 35 text + 0 tables\n",
      "   âœ‚ï¸  39/42 valid chunks\n",
      "   ğŸ“ Saved: privacy_formitraapplication_1.json\n",
      "   ğŸ“ Sizes: 227-1899 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: Customers use of the Application and the Service (a) must strictly be in \n",
      "accordance with this Agreement, and includes only the right to download, ins...\n",
      "\n",
      "[10/14] ğŸ“„ Customer Suitability and Appropriateness_0.pdf\n",
      "   Policy: Customer Suitability and Appropriateness_0.pdf...\n",
      "   ğŸ“Š Extraction: 29,337 chars, 4,073 words\n",
      "   ğŸ“Š Blocks: 71 text + 1 tables\n",
      "   âœ‚ï¸  23/31 valid chunks\n",
      "   ğŸ“ Saved: policyoncustomersuitabilityandappropriateness_1.json\n",
      "   ğŸ“ Sizes: 179-1954 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: FINO Payments Bank Policy on Customer Suitability and\n",
      "\n",
      "\n",
      "Appropriateness Version 10.0 FINO Payments Bank  \n",
      "Policy on Customer Suitability and\n",
      "Appropria...\n",
      "\n",
      "[11/14] ğŸ“„ 1655716940_PolicyforAppointmentofStatutoryauditors.pdf\n",
      "   Policy: 1655716940_PolicyforAppointmentofStatutoryauditors...\n",
      "   ğŸ“Š Extraction: 16,427 chars, 2,667 words\n",
      "   ğŸ“Š Blocks: 44 text + 1 tables\n",
      "   âœ‚ï¸  10/12 valid chunks\n",
      "   ğŸ“ Saved: attached_onappointmentofstatutoryauditors_1.json\n",
      "   ğŸ“ Sizes: 202-1996 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: POLICY FOR A\n",
      "\n",
      "\n",
      "APPOINTMENT OF STA\n",
      "\n",
      "\n",
      "AUDITORS TUTORY POLICY FOR A\n",
      " \n",
      "APPOINTMENT OF STA\n",
      "AUDITORS \n",
      "TUTORY\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "Table of Contents ï‚·\n",
      "Object...\n",
      "\n",
      "[12/14] ğŸ“„ 1749546895_KYCAMLpolicy.pdf\n",
      "   Policy: 1749546895_KYCAMLpolicy.pdf...\n",
      "   ğŸ“Š Extraction: 408,501 chars, 64,000 words\n",
      "   ğŸ“Š Blocks: 2136 text + 11 tables\n",
      "   âœ‚ï¸  207/315 valid chunks\n",
      "   ğŸ“ Saved: kycamlcftpolicy_1.json\n",
      "   ğŸ“ Sizes: 155-1967 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: .2 Directions. Adherences to Know Your Customer (KYC), Anti \n",
      " Money Laundering (AML), and Countering Financing of Terrorism (CFT) Guidelines are few s...\n",
      "\n",
      "[13/14] ğŸ“„ 1744362993_ChequeCollectionPolicy.pdf\n",
      "   Policy: 1744362993_ChequeCollectionPolicy.pdf...\n",
      "   ğŸ“Š Extraction: 24,425 chars, 3,720 words\n",
      "   ğŸ“Š Blocks: 116 text + 3 tables\n",
      "   âœ‚ï¸  14/21 valid chunks\n",
      "   ğŸ“ Saved: chequecollectionpolicy_1.json\n",
      "   ğŸ“ Sizes: 204-1732 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: Cheque Collection Policy V6.0 Cheque Collection Policy INDEX SR \n",
      "No Particulars \n",
      "Page No. Introduction \n",
      "Arrangements for Collection \n",
      "Time Frame for co...\n",
      "\n",
      "[14/14] ğŸ“„ Citizens Charter.pdf\n",
      "   Policy: Citizens Charter.pdf...\n",
      "   ğŸ“Š Extraction: 25,843 chars, 3,456 words\n",
      "   ğŸ“Š Blocks: 144 text + 1 tables\n",
      "   âœ‚ï¸  27/33 valid chunks\n",
      "   ğŸ“ Saved: citizenscharter_1.json\n",
      "   ğŸ“ Sizes: 166-1568 chars\n",
      "--------------------------------------------------------------------------------\n",
      "   ğŸ§ª Sample: Classification: Public FINO Payments Bank Citizenâ€™s Charter Classification: Public FINO Payments Bank \n",
      "Citizenâ€™s Charter\n",
      "\n",
      "=== PAGE BREAK ===\n",
      "\n",
      "Classifi...\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ EXTRACTION + CHUNKING COMPLETE!\n",
      "ğŸ“Š Total chunks: 799\n",
      "ğŸ“ Total chars: 589,221\n",
      "ğŸ“ Chunk files: 14\n",
      "âœ… Extraction report: data/extraction_report.json\n",
      "âœ… All chunks ready for embeddings â†’ data/chunks/\n",
      "\n",
      "ğŸ¯ Next: Cell 5 (Chunk validation + embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Process ALL Active policies \n",
    "active_policies = [p for p in policies if p[\"status\"] == \"Active\"]\n",
    "print(f\"ğŸš€ Processing {len(active_policies)} ACTIVE policies...\\n\")\n",
    "\n",
    "all_chunks = []\n",
    "extraction_summary = []\n",
    "\n",
    "for idx, policy in enumerate(active_policies, 1):\n",
    "    pdf_path = PDF_DIR / policy['file_name']\n",
    "    \n",
    "    # FIXED: Safe policy_name access\n",
    "    policy_name = policy.get('policy_name', policy.get('file_name', 'Unknown Policy'))[:50]\n",
    "    \n",
    "    print(f\"[{idx}/{len(active_policies)}] ğŸ“„ {policy['file_name']}\")\n",
    "    print(f\"   Policy: {policy_name}...\")\n",
    "    \n",
    "    # Universal extraction\n",
    "    full_text, stats = universal_extract(pdf_path)\n",
    "    print(f\"   ğŸ“Š Extraction: {stats['total_chars']:,} chars, {stats['total_words']:,} words\")\n",
    "    print(f\"   ğŸ“Š Blocks: {stats['text_blocks']} text + {stats['table_blocks']} tables\")\n",
    "    \n",
    "    extraction_summary.append({\n",
    "        **policy,\n",
    "        \"policy_name_display\": policy_name,  # Add fallback\n",
    "        \"extraction_stats\": stats\n",
    "    })\n",
    "    \n",
    "    # Semantic chunking with E5-Large (your config)\n",
    "    chunker = SemanticChunker(\n",
    "        embeddings,\n",
    "        breakpoint_threshold_type=\"percentile\",\n",
    "        breakpoint_threshold_amount=85\n",
    "    )\n",
    "    \n",
    "    raw_chunks = chunker.split_text(full_text)\n",
    "    \n",
    "    # Filter + validate chunks (E5 limits)\n",
    "    valid_chunks = []\n",
    "    for i, chunk in enumerate(raw_chunks):\n",
    "        chunk_len = len(chunk)\n",
    "        if 150 <= chunk_len <= E5_MAX_CHUNK_CHARS:  # Your E5 config\n",
    "            valid_chunks.append({\n",
    "                \"policy_id\": policy[\"policy_id\"],\n",
    "                \"version_number\": policy[\"version_number\"],\n",
    "                \"chunk_id\": f\"{policy['policy_id']}_{policy['version_number']}_{i:04d}\",\n",
    "                \"chunk_index\": i,\n",
    "                \"text\": chunk,\n",
    "                \"text_length\": chunk_len,\n",
    "                \"word_count\": len(chunk.split()),\n",
    "                \"metadata\": policy,\n",
    "                \"extraction_stats\": stats\n",
    "            })\n",
    "    \n",
    "    all_chunks.extend(valid_chunks)\n",
    "    \n",
    "    # Save per-policy chunks\n",
    "    policy_chunks_file = CHUNKS_DIR / f\"{policy['policy_id']}_{policy['version_number']}.json\"\n",
    "    with open(policy_chunks_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_chunks, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"   âœ‚ï¸  {len(valid_chunks)}/{len(raw_chunks)} valid chunks\")\n",
    "    print(f\"   ğŸ“ Saved: {policy_chunks_file.name}\")\n",
    "    print(f\"   ğŸ“ Sizes: {min(c['text_length'] for c in valid_chunks) if valid_chunks else 0}-\"\n",
    "          f\"{max(c['text_length'] for c in valid_chunks) if valid_chunks else 0} chars\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Sample first chunk\n",
    "    if valid_chunks:\n",
    "        print(f\"   ğŸ§ª Sample: {valid_chunks[0]['text'][:150]}...\")\n",
    "    print()\n",
    "\n",
    "# Global summary\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ EXTRACTION + CHUNKING COMPLETE!\")\n",
    "print(f\"ğŸ“Š Total chunks: {len(all_chunks):,}\")\n",
    "print(f\"ğŸ“ Total chars: {sum(c['text_length'] for c in all_chunks):,}\")\n",
    "print(f\"ğŸ“ Chunk files: {len(list(CHUNKS_DIR.glob('*.json')))}\")\n",
    "\n",
    "# Save extraction report\n",
    "with open(\"data/extraction_report.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(extraction_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Extraction report: data/extraction_report.json\")\n",
    "print(f\"âœ… All chunks ready for embeddings â†’ data/chunks/\")\n",
    "print(f\"\\nğŸ¯ Next: Cell 5 (Chunk validation + embeddings)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb4a098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing FAQ file...\n",
      "ğŸ“„ FAQ raw: 88,607 chars, 13,783 words\n",
      "âœ‚ï¸ FAQ: 35 chunks â†’ faq_section_1.0.json\n",
      "\n",
      "ğŸ“Š TOTAL (PDFs + FAQ): 834 chunks\n"
     ]
    }
   ],
   "source": [
    "# FAQ Processing (MERGE WITH PDF CHUNKS)\n",
    "print(\"ğŸ“„ Processing FAQ file...\")\n",
    "\n",
    "if FAQ_PATH.exists():\n",
    "    with open(FAQ_PATH, 'r', encoding='utf-8') as f:\n",
    "        faq_text = f.read()\n",
    "    \n",
    "    print(f\"ğŸ“„ FAQ raw: {len(faq_text):,} chars, {len(faq_text.split()):,} words\")\n",
    "    \n",
    "    # FAQ metadata (simple)\n",
    "    faq_metadata = {\n",
    "        \"policy_id\": \"faq_section\",\n",
    "        \"version_number\": \"1.0\",\n",
    "        \"status\": \"Active\",\n",
    "        \"effective_date_ts\": int(datetime.now().timestamp()),\n",
    "        \"expiry_date_ts\": 4102425000,  # 2100\n",
    "        \"effective_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"expiry_date\": \"2100-01-01\",\n",
    "        \"language\": \"en\",\n",
    "        \"file_name\": FAQ_PATH.name,\n",
    "        \"policy_name\": \"Fino Bank FAQs (Website)\",\n",
    "        \"sr\": \"FAQ-001\"\n",
    "    }\n",
    "    \n",
    "    # Semantic chunk FAQ\n",
    "    faq_chunker = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "    faq_raw_chunks = faq_chunker.split_text(faq_text)\n",
    "    \n",
    "    faq_chunks = []\n",
    "    for i, chunk in enumerate(faq_raw_chunks):\n",
    "        chunk_len = len(chunk)\n",
    "        if 150 <= chunk_len <= 4000:\n",
    "            faq_chunks.append({\n",
    "                \"policy_id\": \"faq_section\",\n",
    "                \"version_number\": \"1.0\",\n",
    "                \"chunk_id\": f\"faq_section_1.0_{i:04d}\",\n",
    "                \"chunk_index\": i,\n",
    "                \"text\": chunk,\n",
    "                \"text_length\": chunk_len,\n",
    "                \"word_count\": len(chunk.split()),\n",
    "                \"metadata\": faq_metadata,\n",
    "                \"extraction_stats\": {\n",
    "                    \"total_chars\": len(faq_text),\n",
    "                    \"total_words\": len(faq_text.split()),\n",
    "                    \"source\": \"faq_txt\"\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Save FAQ chunks\n",
    "    faq_output = CHUNKS_DIR / \"faq_section_1.0.json\"\n",
    "    with open(faq_output, 'w', encoding='utf-8') as f:\n",
    "        json.dump(faq_chunks, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    all_chunks.extend(faq_chunks)\n",
    "    print(f\"âœ‚ï¸ FAQ: {len(faq_chunks)} chunks â†’ {faq_output.name}\")\n",
    "    \n",
    "    extraction_summary.append({\n",
    "        **faq_metadata,\n",
    "        \"extraction_stats\": {\n",
    "            \"total_chars\": len(faq_text),\n",
    "            \"total_words\": len(faq_text.split()),\n",
    "            \"source\": \"faq_txt\"\n",
    "        }\n",
    "    })\n",
    "else:\n",
    "    print(\"âš ï¸ FAQ file not found: data/raw/faqs.txt\")\n",
    "\n",
    "print(f\"\\nğŸ“Š TOTAL (PDFs + FAQ): {len(all_chunks):,} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327eeb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Found 15 chunk files\n",
      "Sample chunk files:\n",
      "   attached_onappointmentofstatutoryauditors_1.json: 10 chunks\n",
      "   bsbdapolicy_1.json: 29 chunks\n",
      "   chequecollectionpolicy_1.json: 14 chunks\n",
      "   citizenscharter_1.json: 27 chunks\n",
      "   codeofbankscommittmenttocustomers_1.json: 44 chunks\n",
      "âœ… Loaded 10 chunks from attached_onappointmentofstatutoryauditors_1.json\n",
      "âœ… Loaded 29 chunks from bsbdapolicy_1.json\n",
      "âœ… Loaded 14 chunks from chequecollectionpolicy_1.json\n",
      "âœ… Loaded 27 chunks from citizenscharter_1.json\n",
      "âœ… Loaded 44 chunks from codeofbankscommittmenttocustomers_1.json\n",
      "âœ… Loaded 68 chunks from comprehensivedepositpolicy_7.json\n",
      "âœ… Loaded 36 chunks from customercompensationpolicy_1.json\n",
      "âœ… Loaded 23 chunks from customergrievancepolicy_1.json\n",
      "âœ… Loaded 179 chunks from customerservicepolicy_1.json\n",
      "âœ… Loaded 29 chunks from deceasedclaimsettlementpolicy_1.json\n",
      "âœ… Loaded 35 chunks from faq_section_1.0.json\n",
      "âœ… Loaded 207 chunks from kycamlcftpolicy_1.json\n",
      "âœ… Loaded 23 chunks from policyoncustomersuitabilityandappropriateness_1.json\n",
      "âœ… Loaded 39 chunks from privacy_formitraapplication_1.json\n",
      "âœ… Loaded 71 chunks from revisedkyc_wef2ndmay2023_1.json\n",
      "\n",
      "ğŸ“Š TOTAL: 834 chunks ready for E5 embedding\n",
      "ğŸ“ Chunk sizes: 153 - 3668 chars\n",
      "\n",
      "ğŸ“ˆ Quality stats (E5-Large optimized):\n",
      "   total_chunks: 834\n",
      "   avg_length: 761.2\n",
      "   policies_covered: 15\n",
      "   avg_words: 115.7\n",
      "   max_chunk_chars: 3668\n",
      "   min_chunk_chars: 153\n",
      "\n",
      "âš ï¸  7 chunks exceed E5 limit (2000 chars)\n",
      "\n",
      "âœ… Chunks validated â†’ Ready for E5-Large embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load & Validate All Chunks (E5-Large)\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# Verify chunking results first\n",
    "chunk_files = list(CHUNKS_DIR.glob(\"*.json\"))\n",
    "print(f\"ğŸ“ Found {len(chunk_files)} chunk files\")\n",
    "print(\"Sample chunk files:\")\n",
    "for f in chunk_files[:5]:\n",
    "    with open(f, 'r', encoding='utf-8') as ff:\n",
    "        chunks = json.load(ff)\n",
    "    print(f\"   {f.name}: {len(chunks)} chunks\")\n",
    "\n",
    "# Load ALL chunks (PDFs + FAQ)\n",
    "all_policy_chunks = []\n",
    "for chunk_file in sorted(chunk_files):\n",
    "    with open(chunk_file, 'r', encoding='utf-8') as f:\n",
    "        policy_chunks = json.load(f)\n",
    "    all_policy_chunks.extend(policy_chunks)\n",
    "    print(f\"âœ… Loaded {len(policy_chunks):,} chunks from {chunk_file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š TOTAL: {len(all_policy_chunks):,} chunks ready for E5 embedding\")\n",
    "print(f\"ğŸ“ Chunk sizes: {min(c['text_length'] for c in all_policy_chunks)} - \"\n",
    "      f\"{max(c['text_length'] for c in all_policy_chunks)} chars\")\n",
    "\n",
    "# Chunk quality check (E5-safe)\n",
    "chunk_stats = {\n",
    "    \"total_chunks\": len(all_policy_chunks),\n",
    "    \"avg_length\": sum(c['text_length'] for c in all_policy_chunks) / len(all_policy_chunks),\n",
    "    \"policies_covered\": len(set(c['policy_id'] for c in all_policy_chunks)),\n",
    "    \"avg_words\": sum(c['word_count'] for c in all_policy_chunks) / len(all_policy_chunks),\n",
    "    \"max_chunk_chars\": max(c['text_length'] for c in all_policy_chunks),\n",
    "    \"min_chunk_chars\": min(c['text_length'] for c in all_policy_chunks)\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Quality stats (E5-Large optimized):\")\n",
    "for k, v in chunk_stats.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"   {k}: {v:.1f}\")\n",
    "    else:\n",
    "        print(f\"   {k}: {v}\")\n",
    "\n",
    "# E5 constraint check\n",
    "unsafe_chunks = [c for c in all_policy_chunks if c['text_length'] > E5_MAX_CHUNK_CHARS]\n",
    "if unsafe_chunks:\n",
    "    print(f\"\\nâš ï¸  {len(unsafe_chunks)} chunks exceed E5 limit ({E5_MAX_CHUNK_CHARS} chars)\")\n",
    "else:\n",
    "    print(f\"\\nâœ… All chunks safe for E5 embedding (max {E5_MAX_CHUNK_CHARS} chars)\")\n",
    "\n",
    "print(\"\\nâœ… Chunks validated â†’ Ready for E5-Large embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0746406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name D:/models/e5-large. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading E5-Large embeddings (multilingual, local)...\n",
      "âœ… E5-Large test embedding: 1024 dimensions\n",
      "   Model: multilingual-e5-large (local)\n",
      "   Embedding type: Dense (cosine similarity)\n",
      "   Normalization: L2 normalized\n",
      "\n",
      "ğŸš€ Generating E5-Large embeddings for all chunks...\n",
      "   Progress: 32/834 chunks (3.8%)\n",
      "   Progress: 64/834 chunks (7.7%)\n",
      "   Progress: 96/834 chunks (11.5%)\n",
      "   Progress: 128/834 chunks (15.3%)\n",
      "   Progress: 160/834 chunks (19.2%)\n",
      "   Progress: 192/834 chunks (23.0%)\n",
      "   Progress: 224/834 chunks (26.9%)\n",
      "   Progress: 256/834 chunks (30.7%)\n",
      "   Progress: 288/834 chunks (34.5%)\n",
      "   Progress: 320/834 chunks (38.4%)\n",
      "   Progress: 352/834 chunks (42.2%)\n",
      "   Progress: 384/834 chunks (46.0%)\n",
      "   Progress: 416/834 chunks (49.9%)\n",
      "   Progress: 448/834 chunks (53.7%)\n",
      "   Progress: 480/834 chunks (57.6%)\n",
      "   Progress: 512/834 chunks (61.4%)\n",
      "   Progress: 544/834 chunks (65.2%)\n",
      "   Progress: 576/834 chunks (69.1%)\n",
      "   Progress: 608/834 chunks (72.9%)\n",
      "   Progress: 640/834 chunks (76.7%)\n",
      "   Progress: 672/834 chunks (80.6%)\n",
      "   Progress: 704/834 chunks (84.4%)\n",
      "   Progress: 736/834 chunks (88.2%)\n",
      "   Progress: 768/834 chunks (92.1%)\n",
      "   Progress: 800/834 chunks (95.9%)\n",
      "   Progress: 832/834 chunks (99.8%)\n",
      "   Progress: 834/834 chunks (100.0%)\n",
      "\n",
      "âœ… Generated 834 E5-Large embeddings\n",
      "ğŸ“Š Embedding dimension: 1024\n",
      "ğŸ“Š All embeddings normalized (L2)\n",
      "âœ… Embeddings metadata backup: data/embeddings_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Generate E5-Large Dense Embeddings\n",
    "import numpy as np\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"ğŸ”„ Loading E5-Large embeddings (multilingual, local)...\")\n",
    "\n",
    "# E5-Large already loaded from Cell 3\n",
    "# Verify it's ready\n",
    "e5_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"D:/models/e5-large\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Test embedding on first chunk\n",
    "test_chunk = all_policy_chunks[0]['text'][:500]\n",
    "test_embedding = e5_embeddings.embed_query(test_chunk)\n",
    "print(f\"âœ… E5-Large test embedding: {len(test_embedding)} dimensions\")\n",
    "print(f\"   Model: multilingual-e5-large (local)\")\n",
    "print(f\"   Embedding type: Dense (cosine similarity)\")\n",
    "print(f\"   Normalization: L2 normalized\")\n",
    "\n",
    "# Generate embeddings for ALL chunks (BATCHED for efficiency)\n",
    "print(\"\\nğŸš€ Generating E5-Large embeddings for all chunks...\")\n",
    "\n",
    "all_embeddings_data = []\n",
    "batch_size = 32  # E5 batch size for CPU\n",
    "total_batches = (len(all_policy_chunks) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_idx in range(0, len(all_policy_chunks), batch_size):\n",
    "    batch_end = min(batch_idx + batch_size, len(all_policy_chunks))\n",
    "    batch_chunks = all_policy_chunks[batch_idx:batch_end]\n",
    "    \n",
    "    # Extract texts for batch\n",
    "    batch_texts = [c['text'] for c in batch_chunks]\n",
    "    \n",
    "    # E5 embedding (dense only - no sparse for local model)\n",
    "    batch_embeddings = e5_embeddings.embed_documents(batch_texts)\n",
    "    \n",
    "    # Attach embeddings to chunks\n",
    "    for i, (chunk, embedding) in enumerate(zip(batch_chunks, batch_embeddings)):\n",
    "        all_embeddings_data.append({\n",
    "            **chunk,\n",
    "            \"dense_embedding\": embedding,\n",
    "            \"embedding_model\": \"e5-large\",\n",
    "            \"embedding_dims\": len(embedding)\n",
    "        })\n",
    "    \n",
    "    progress = (batch_end / len(all_policy_chunks)) * 100\n",
    "    print(f\"   Progress: {batch_end}/{len(all_policy_chunks)} chunks ({progress:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(all_embeddings_data)} E5-Large embeddings\")\n",
    "print(f\"ğŸ“Š Embedding dimension: {len(all_embeddings_data[0]['dense_embedding'])}\")\n",
    "print(f\"ğŸ“Š All embeddings normalized (L2)\")\n",
    "\n",
    "# Save embeddings locally (backup)\n",
    "embeddings_backup = []\n",
    "for data in all_embeddings_data:\n",
    "    embeddings_backup.append({\n",
    "        \"chunk_id\": data['chunk_id'],\n",
    "        \"embedding_dims\": data['embedding_dims'],\n",
    "        \"embedding_model\": data['embedding_model']\n",
    "    })\n",
    "\n",
    "with open(\"data/embeddings_metadata.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(embeddings_backup, f, indent=2)\n",
    "\n",
    "print(\"âœ… Embeddings metadata backup: data/embeddings_metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1196d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Building Pinecone vectors from E5 embeddings...\n",
      "âœ… Built 834 Pinecone vectors\n",
      "ğŸ“ Vector dimension: 1024\n",
      "ğŸ“Š Metadata keys: ['policy_id', 'version_number', 'status', 'effective_date_ts', 'expiry_date_ts']...\n",
      "\n",
      "ğŸ§ª Sample vector:\n",
      "   ID: attached_onappointmentofstatutoryauditors_1_0000\n",
      "   Dimension: 1024\n",
      "   Policy: attached_onappointmentofstatutoryauditors\n",
      "   Status: Active\n",
      "\n",
      "âœ… Vector structure backup: data/pinecone_vectors_structure.json\n",
      "âœ… Ready for Pinecone upload\n"
     ]
    }
   ],
   "source": [
    "# Build Pinecone-Ready Vectors (E5-Large) - format -> id(chunk id), values(1024 floats), metadata\n",
    "# Means merge embedding and metadata\n",
    "print(\"ğŸ”„ Building Pinecone vectors from E5 embeddings...\")\n",
    "\n",
    "pinecone_vectors = []\n",
    "\n",
    "for data in all_embeddings_data:\n",
    "    # Build metadata dict (banking + temporal critical)\n",
    "    metadata = {\n",
    "        **data['metadata'],  # All original metadata\n",
    "        \"chunk_id\": data['chunk_id'],\n",
    "        \"chunk_index\": data['chunk_index'],\n",
    "        \"text_length\": data['text_length'],\n",
    "        \"word_count\": data['word_count'],\n",
    "        \"embedding_model\": \"e5-large\",\n",
    "        \"text_preview\": data['text'][:200] + \"...\" if len(data['text']) > 200 else data['text']\n",
    "    }\n",
    "    \n",
    "    # Pinecone vector (E5 dense only)\n",
    "    vector = {\n",
    "        \"id\": data['chunk_id'],\n",
    "        \"values\": data['dense_embedding'],  # E5 dense (1024-dim)\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    \n",
    "    pinecone_vectors.append(vector)\n",
    "\n",
    "print(f\"âœ… Built {len(pinecone_vectors)} Pinecone vectors\")\n",
    "print(f\"ğŸ“ Vector dimension: {len(pinecone_vectors[0]['values'])}\")\n",
    "print(f\"ğŸ“Š Metadata keys: {list(pinecone_vectors[0]['metadata'].keys())[:5]}...\")\n",
    "\n",
    "# Sample vector structure\n",
    "print(f\"\\nğŸ§ª Sample vector:\")\n",
    "print(f\"   ID: {pinecone_vectors[0]['id']}\")\n",
    "print(f\"   Dimension: {len(pinecone_vectors[0]['values'])}\")\n",
    "print(f\"   Policy: {pinecone_vectors[0]['metadata']['policy_id']}\")\n",
    "print(f\"   Status: {pinecone_vectors[0]['metadata'].get('status', 'N/A')}\")\n",
    "\n",
    "# Save Pinecone vectors to disk (backup before upload)\n",
    "vectors_backup = []\n",
    "for v in pinecone_vectors:\n",
    "    vectors_backup.append({\n",
    "        \"id\": v['id'],\n",
    "        \"dimension\": len(v['values']),\n",
    "        \"metadata_keys\": list(v['metadata'].keys())\n",
    "    })\n",
    "\n",
    "with open(\"data/pinecone_vectors_structure.json\", 'w') as f:\n",
    "    json.dump(vectors_backup, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Vector structure backup: data/pinecone_vectors_structure.json\")\n",
    "print(f\"âœ… Ready for Pinecone upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86061fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Initializing Pinecone with API key...\n",
      "ğŸ“‹ Existing indexes: []\n",
      "ğŸ”„ Creating Pinecone index: fino-policies-e5\n",
      "   Dimension: 1024\n",
      "   Metric: cosine\n",
      "   Type: Serverless\n",
      "âœ… Index created: fino-policies-e5\n",
      "\n",
      "ğŸ“Š Index stats:\n",
      "   Total vectors: 0\n",
      "   Namespaces: []\n",
      "   Ready for vectors\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone Index (E5-Large config)\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Pinecone config \n",
    "PINECONE_INDEX_NAME = \"fino-policies-e5\"  # E5-specific index\n",
    "E5_EMBEDDING_DIM = 1024  # E5-Large dimension\n",
    "\n",
    "# Initialize Pinecone\n",
    "print(f\"ğŸ”„ Initializing Pinecone with API key...\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# List existing indexes\n",
    "print(f\"ğŸ“‹ Existing indexes: {[idx.name for idx in pc.list_indexes()]}\")\n",
    "\n",
    "# Check if index exists\n",
    "if PINECONE_INDEX_NAME not in [idx.name for idx in pc.list_indexes()]:\n",
    "    print(f\"ğŸ”„ Creating Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "    print(f\"   Dimension: {E5_EMBEDDING_DIM}\")\n",
    "    print(f\"   Metric: cosine\")\n",
    "    print(f\"   Type: Serverless\")\n",
    "    \n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=E5_EMBEDDING_DIM,\n",
    "        metric=\"cosine\",  # E5 uses cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"âœ… Index created: {PINECONE_INDEX_NAME}\")\n",
    "else:\n",
    "    print(f\"âœ… Index exists: {PINECONE_INDEX_NAME}\")\n",
    "\n",
    "# Connect to index\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# Get index stats\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nğŸ“Š Index stats:\")\n",
    "print(f\"   Total vectors: {stats['total_vector_count']:,}\")\n",
    "print(f\"   Namespaces: {list(stats['namespaces'].keys())}\")\n",
    "print(f\"   Ready for vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a359f961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing single E5 vector upsert...\n",
      "âœ… Single upsert successful\n",
      "   Upserted ID: attached_onappointmentofstatutoryauditors_1_0000\n",
      "   Response: UpsertResponse(upserted_count=1, _response_info={'raw_headers': {'date': 'Tue, 30 Dec 2025 06:40:10 GMT', 'content-type': 'application/json', 'content-length': '19', 'connection': 'keep-alive', 'x-pinecone-request-lsn': '1', 'x-pinecone-request-logical-size': '5051', 'x-pinecone-request-latency-ms': '865', 'x-pinecone-request-id': '5484493862748635679', 'x-envoy-upstream-service-time': '380', 'x-pinecone-response-duration-ms': '867', 'grpc-status': '0', 'server': 'envoy'}})\n",
      "\n",
      "ğŸ” Testing E5 retrieval...\n",
      "âœ… Query returned 1 matches:\n",
      "\n",
      "   [1] Score: 0.7847\n",
      "       ID: attached_onappointmentofstatutoryauditors_1_0000\n",
      "       Policy: attached_onappointmentofstatutoryauditors\n",
      "       Preview: POLICY FOR A\n",
      "\n",
      "\n",
      "APPOINTMENT OF STA\n",
      "\n",
      "\n",
      "AUDITORS TUTORY POLICY FOR A\n",
      " \n",
      "APPOINTMENT OF STA\n",
      "AUDITORS \n",
      "TUTO...\n",
      "\n",
      "âœ… E5 vector upsert & retrieval working perfectly!\n"
     ]
    }
   ],
   "source": [
    "# Test E5 vector upsert (safety check)\n",
    "print(\"ğŸ§ª Testing single E5 vector upsert...\")\n",
    "\n",
    "test_vector = pinecone_vectors[0]\n",
    "\n",
    "# Test upsert to isolated namespace\n",
    "test_upsert = index.upsert(\n",
    "    vectors=[test_vector],\n",
    "    namespace=\"fino-test-e5\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Single upsert successful\")\n",
    "print(f\"   Upserted ID: {test_vector['id']}\")\n",
    "print(f\"   Response: {test_upsert}\")\n",
    "\n",
    "# Test retrieval (critical!)\n",
    "print(f\"\\nğŸ” Testing E5 retrieval...\")\n",
    "\n",
    "# Create test query embedding\n",
    "test_query_text = \"savings account minimum balance\"\n",
    "test_query_embedding = e5_embeddings.embed_query(test_query_text)\n",
    "\n",
    "# Query test namespace\n",
    "test_results = index.query(\n",
    "    vector=test_query_embedding,\n",
    "    top_k=3,\n",
    "    namespace=\"fino-test-e5\",\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Query returned {len(test_results['matches'])} matches:\")\n",
    "for i, match in enumerate(test_results['matches'], 1):\n",
    "    print(f\"\\n   [{i}] Score: {match['score']:.4f}\")\n",
    "    print(f\"       ID: {match['id']}\")\n",
    "    print(f\"       Policy: {match['metadata'].get('policy_id', 'N/A')}\")\n",
    "    print(f\"       Preview: {match['metadata'].get('text_preview', 'N/A')[:100]}...\")\n",
    "\n",
    "print(f\"\\nâœ… E5 vector upsert & retrieval working perfectly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488d47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full production batch upsert (E5)\n",
    "# print(\"ğŸš€ PRODUCTION UPSERT: All E5 vectors to Pinecone\")\n",
    "# print(f\"ğŸ“¤ {len(pinecone_vectors):,} vectors â†’ fino-policies namespace\")\n",
    "\n",
    "# # Pinecone batch limits: 100MB / request, typically 1000 vectors safe\n",
    "# batch_size = 500\n",
    "# namespace = \"fino-policies-e5\"\n",
    "\n",
    "# total_upserted = 0\n",
    "# for batch_idx in range(0, len(pinecone_vectors), batch_size):\n",
    "#     batch_end = min(batch_idx + batch_size, len(pinecone_vectors))\n",
    "#     batch = pinecone_vectors[batch_idx:batch_end]\n",
    "    \n",
    "#     # Upsert batch\n",
    "#     response = index.upsert(\n",
    "#         vectors=batch,\n",
    "#         namespace=namespace\n",
    "#     )\n",
    "    \n",
    "#     total_upserted += len(batch)\n",
    "#     progress = (batch_end / len(pinecone_vectors)) * 100\n",
    "    \n",
    "#     print(f\"   Batch {(batch_idx // batch_size) + 1}: {len(batch)} vectors \"\n",
    "#           f\"({progress:.1f}%) â†’ {response}\")\n",
    "\n",
    "# print(f\"\\nâœ… UPSERT COMPLETE!\")\n",
    "# print(f\"   Total vectors: {total_upserted:,}\")\n",
    "# print(f\"   Namespace: {namespace}\")\n",
    "# print(f\"   Model: E5-Large\")\n",
    "\n",
    "# # Final index stats\n",
    "# final_stats = index.describe_index_stats()\n",
    "# print(f\"\\nğŸ“Š Final Pinecone stats:\")\n",
    "# print(f\"   Total vectors: {final_stats['total_vector_count']:,}\")\n",
    "# print(f\"   Namespaces: {list(final_stats['namespaces'].keys())}\")\n",
    "# for ns, ns_stats in final_stats['namespaces'].items():\n",
    "#     print(f\"      {ns}: {ns_stats['vector_count']:,} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54252b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ SAFE PRODUCTION UPSERT (network-friendly)\n",
      "ğŸ“¤ Total vectors: 834\n",
      "âš ï¸ Batch 1/34 attempt 1 failed\n",
      "âš ï¸ Batch 1/34 attempt 2 failed\n",
      "âš ï¸ Batch 1/34 attempt 3 failed\n",
      "âŒ Batch 1 skipped after retries\n",
      "âš ï¸ Batch 2/34 attempt 1 failed\n",
      "âš ï¸ Batch 2/34 attempt 2 failed\n",
      "âš ï¸ Batch 2/34 attempt 3 failed\n",
      "âŒ Batch 2 skipped after retries\n",
      "âš ï¸ Batch 3/34 attempt 1 failed\n",
      "âš ï¸ Batch 3/34 attempt 2 failed\n",
      "âš ï¸ Batch 3/34 attempt 3 failed\n",
      "âŒ Batch 3 skipped after retries\n",
      "âš ï¸ Batch 4/34 attempt 1 failed\n",
      "âš ï¸ Batch 4/34 attempt 2 failed\n",
      "âš ï¸ Batch 4/34 attempt 3 failed\n",
      "âŒ Batch 4 skipped after retries\n",
      "âš ï¸ Batch 5/34 attempt 1 failed\n",
      "âš ï¸ Batch 5/34 attempt 2 failed\n",
      "âš ï¸ Batch 5/34 attempt 3 failed\n",
      "âŒ Batch 5 skipped after retries\n",
      "âš ï¸ Batch 6/34 attempt 1 failed\n",
      "âš ï¸ Batch 6/34 attempt 2 failed\n",
      "âš ï¸ Batch 6/34 attempt 3 failed\n",
      "âŒ Batch 6 skipped after retries\n",
      "âš ï¸ Batch 7/34 attempt 1 failed\n",
      "âš ï¸ Batch 7/34 attempt 2 failed\n",
      "âš ï¸ Batch 7/34 attempt 3 failed\n",
      "âŒ Batch 7 skipped after retries\n",
      "âš ï¸ Batch 8/34 attempt 1 failed\n",
      "âš ï¸ Batch 8/34 attempt 2 failed\n",
      "âš ï¸ Batch 8/34 attempt 3 failed\n",
      "âŒ Batch 8 skipped after retries\n",
      "âš ï¸ Batch 9/34 attempt 1 failed\n",
      "âš ï¸ Batch 9/34 attempt 2 failed\n",
      "âš ï¸ Batch 9/34 attempt 3 failed\n",
      "âŒ Batch 9 skipped after retries\n",
      "âš ï¸ Batch 10/34 attempt 1 failed\n",
      "âš ï¸ Batch 10/34 attempt 2 failed\n",
      "âš ï¸ Batch 10/34 attempt 3 failed\n",
      "âŒ Batch 10 skipped after retries\n",
      "âš ï¸ Batch 11/34 attempt 1 failed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connection.py:204\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\socket.py:967\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    966\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    968\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connection.py:759\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    758\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m: HTTPSConnection(host='fino-policies-e5-1l9k5zf.svc.aped-4627-b74a.pinecone.io', port=443): Failed to resolve 'fino-policies-e5-1l9k5zf.svc.aped-4627-b74a.pinecone.io' ([Errno 11001] getaddrinfo failed)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m         success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\utils\\error_handling.py:27\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Lazy import of urllib3 exceptions\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaxRetryError, ProtocolError \u001b[38;5;28;01mas\u001b[39;00m Urllib3ProtocolError\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\db_data\\index.py:446\u001b[0m, in \u001b[0;36mIndex.upsert\u001b[1;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req is not supported when batch_size is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upsert in parallel, please follow: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    443\u001b[0m     )\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 446\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upsert_batch(vectors, namespace, _check_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m# If async_req=True, result is an ApplyResult[OpenAPIUpsertResponse]\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# We need to wrap it to convert to our dataclass when .get() is called\u001b[39;00m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;66;03m# result is ApplyResult when async_req=True\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\db_data\\index.py:496\u001b[0m, in \u001b[0;36mIndex._upsert_batch\u001b[1;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_upsert_batch\u001b[39m(\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    488\u001b[0m     vectors: (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m UpsertResponse \u001b[38;5;241m|\u001b[39m ApplyResult:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# Convert OpenAPI UpsertResponse to dataclass UpsertResponse\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mupsert_vectors(\n\u001b[0;32m    497\u001b[0m         IndexRequestFactory\u001b[38;5;241m.\u001b[39mupsert_request(vectors, namespace, _check_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_openapi_kwargs(kwargs),\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# If async_req=True, result is an ApplyResult[OpenAPIUpsertResponse]\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# We need to wrap it in a transformer that converts to our dataclass\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;66;03m# Return ApplyResult - it will be unwrapped by the caller\u001b[39;00m\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# The ApplyResult contains OpenAPIUpsertResponse which will be converted when .get() is called\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:102\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\core\\openapi\\db_data\\api\\vector_operations_api.py:893\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__upsert_vectors\u001b[1;34m(self, upsert_request, x_pinecone_api_version, **kwargs)\u001b[0m\n\u001b[0;32m    890\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_pinecone_api_version\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x_pinecone_api_version\n\u001b[0;32m    891\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupsert_request\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m upsert_request\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m--> 893\u001b[0m     UpsertResponse \u001b[38;5;241m|\u001b[39m ApplyResult[UpsertResponse], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_with_http_info(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    894\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m params \u001b[38;5;241m=\u001b[39m EndpointUtils\u001b[38;5;241m.\u001b[39mgather_params(\n\u001b[0;32m    125\u001b[0m     attribute_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map,\n\u001b[0;32m    126\u001b[0m     location_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_map,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    130\u001b[0m )\n\u001b[0;32m    132\u001b[0m HeaderUtil\u001b[38;5;241m.\u001b[39mprepare_headers(headers_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders_map, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_threadpool_executor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\api_client.py:320\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[0;32m    301\u001b[0m         resource_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m         _check_type,\n\u001b[0;32m    317\u001b[0m     )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[0;32m    341\u001b[0m     (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m     ),\n\u001b[0;32m    359\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\api_client.py:173\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m url \u001b[38;5;241m=\u001b[39m build_request_url(\n\u001b[0;32m    165\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    166\u001b[0m     processed_path_params\u001b[38;5;241m=\u001b[39mpath_params_tuple,\n\u001b[0;32m    167\u001b[0m     resource_path\u001b[38;5;241m=\u001b[39mresource_path,\n\u001b[0;32m    168\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    184\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\api_client.py:400\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[0;32m    391\u001b[0m         url,\n\u001b[0;32m    392\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[0;32m    411\u001b[0m         url,\n\u001b[0;32m    412\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    418\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:146\u001b[0m, in \u001b[0;36mRestClientInterface.POST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mPOST\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    138\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    145\u001b[0m ):\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\pinecone\\openapi_support\\rest_urllib3.py:193\u001b[0m, in \u001b[0;36mUrllib3RestClient.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# content_type == \"application/json\":\u001b[39;00m\n\u001b[0;32m    192\u001b[0m             request_body \u001b[38;5;241m=\u001b[39m orjson\u001b[38;5;241m.\u001b[39mdumps(body)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 193\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m content_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/x-www-form-urlencoded\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_manager\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    204\u001b[0m         method,\n\u001b[0;32m    205\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    211\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    145\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\poolmanager.py:457\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    455\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    459\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "    \u001b[1;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m    841\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    842\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    843\u001b[0m )\n\u001b[1;32m--> 844\u001b[0m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m err \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\util\\retry.py:363\u001b[0m, in \u001b[0;36mRetry.sleep\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m slept:\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\risha\\anaconda3\\envs\\fino\\lib\\site-packages\\urllib3\\util\\retry.py:347\u001b[0m, in \u001b[0;36mRetry._sleep_backoff\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backoff \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pinecone.exceptions import PineconeException\n",
    "\n",
    "print(\"ğŸš€ SAFE PRODUCTION UPSERT (network-friendly)\")\n",
    "print(f\"ğŸ“¤ Total vectors: {len(pinecone_vectors):,}\")\n",
    "\n",
    "batch_size = 25          # ğŸ‘ˆ very small, network-safe\n",
    "namespace = \"fino-policies-e5\"\n",
    "sleep_seconds = 1.5      # ğŸ‘ˆ network ko saans lene do\n",
    "max_retries = 3\n",
    "\n",
    "total_upserted = 0\n",
    "failed_batches = []\n",
    "\n",
    "num_batches = (len(pinecone_vectors) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_idx in range(0, len(pinecone_vectors), batch_size):\n",
    "    batch_no = (batch_idx // batch_size) + 1\n",
    "    batch_end = min(batch_idx + batch_size, len(pinecone_vectors))\n",
    "    batch = pinecone_vectors[batch_idx:batch_end]\n",
    "\n",
    "    success = False\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            index.upsert(\n",
    "                vectors=batch,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            success = True\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Batch {batch_no}/{num_batches} attempt {attempt} failed\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    if success:\n",
    "        total_upserted += len(batch)\n",
    "        progress = (total_upserted / len(pinecone_vectors)) * 100\n",
    "        print(f\"âœ… Batch {batch_no}/{num_batches} \"\n",
    "              f\"â†’ {len(batch)} vectors uploaded \"\n",
    "              f\"({progress:.1f}%)\")\n",
    "    else:\n",
    "        failed_batches.append(batch_no)\n",
    "        print(f\"âŒ Batch {batch_no} skipped after retries\")\n",
    "\n",
    "    time.sleep(sleep_seconds)\n",
    "\n",
    "print(\"\\nğŸ‰ UPSERT PROCESS FINISHED\")\n",
    "print(f\"   Uploaded vectors: {total_upserted:,}\")\n",
    "print(f\"   Failed batches: {failed_batches if failed_batches else 'None'}\")\n",
    "\n",
    "# Final stats (best-effort)\n",
    "try:\n",
    "    stats = index.describe_index_stats()\n",
    "    print(\"\\nğŸ“Š Pinecone index stats:\")\n",
    "    for ns, ns_stats in stats[\"namespaces\"].items():\n",
    "        print(f\"   {ns}: {ns_stats['vector_count']:,} vectors\")\n",
    "except Exception:\n",
    "    print(\"âš ï¸ Could not fetch final stats (network)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09c2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
